---
title: 眼动跟踪
description: 了解眼动跟踪HoloLens 2在全息体验中提供时，了解人类理解的新水平。
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: 眼动跟踪， 混合现实， 输入， 眼睛凝视， 校准， 混合现实头戴显示设备， Windows 混合现实头戴显示设备， 虚拟现实头戴显示设备， HoloLens， MRTK， 混合现实工具包， 意向， 操作
ms.openlocfilehash: 4dac059f72dd043802286081a54137c392c1e912
ms.sourcegitcommit: c65759b8d6465b6b13925cacab5af74443f7e6bd
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 06/15/2021
ms.locfileid: "112110118"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="6ec84-104">HoloLens 2 中的眼动跟踪</span><span class="sxs-lookup"><span data-stu-id="6ec84-104">Eye tracking on HoloLens 2</span></span>

![MRTK 中的眼动跟踪演示](images/mrtk_et_scenemenu.jpg)

<span data-ttu-id="6ec84-106">HoloLens 2可让开发人员使用有关用户正在查看的内容的信息，从而在全息体验中实现新级别的上下文和人类理解。</span><span class="sxs-lookup"><span data-stu-id="6ec84-106">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability to use information about what the user is looking at.</span></span> <span data-ttu-id="6ec84-107">本页介绍开发人员如何从各种用例的眼动跟踪中获益，以及设计基于眼睛凝视的用户交互时要查找的内容。</span><span class="sxs-lookup"><span data-stu-id="6ec84-107">This page explains how developers can benefit from eye tracking for various use cases, and what to look for when designing eye-gaze-based user interactions.</span></span> 

<span data-ttu-id="6ec84-108">眼动跟踪 API 在设计时已考虑用户的隐私，避免传递任何可识别信息，尤其是任何生物识别。</span><span class="sxs-lookup"><span data-stu-id="6ec84-108">Eye tracking API has been designed with a user’s privacy in mind, avoiding passing any identifiable information, particularly any biometrics.</span></span> <span data-ttu-id="6ec84-109">对于支持眼动跟踪的应用程序，用户需要授予应用使用眼动跟踪信息的权限。</span><span class="sxs-lookup"><span data-stu-id="6ec84-109">For eye-tracking capable applications, the user needs to grant app permission to use eye tracking information.</span></span>

### <a name="device-support"></a><span data-ttu-id="6ec84-110">设备支持</span><span class="sxs-lookup"><span data-stu-id="6ec84-110">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="6ec84-111"><strong>功能</strong></span><span class="sxs-lookup"><span data-stu-id="6ec84-111"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="6ec84-112"><a href="/hololens/hololens1-hardware"><strong>HoloLens（第 1 代）</strong></a></span><span class="sxs-lookup"><span data-stu-id="6ec84-112"><a href="/hololens/hololens1-hardware"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="6ec84-113"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="6ec84-113"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="6ec84-114"><a href="../discover/immersive-headset-hardware-details.md"><strong>沉浸式头戴显示设备</strong></a></span><span class="sxs-lookup"><span data-stu-id="6ec84-114"><a href="../discover/immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="6ec84-115">眼睛凝视</span><span class="sxs-lookup"><span data-stu-id="6ec84-115">Eye-gaze</span></span></td>
     <td>❌</td>
     <td><span data-ttu-id="6ec84-116">✔️</span><span class="sxs-lookup"><span data-stu-id="6ec84-116">✔️</span></span></td>
     <td>❌</td>
</tr>
</table>

<br>

## <a name="head-and-eye-tracking-design-concepts-demo"></a><span data-ttu-id="6ec84-117">头部和眼动跟踪设计概念演示</span><span class="sxs-lookup"><span data-stu-id="6ec84-117">Head and eye tracking design concepts demo</span></span>

<span data-ttu-id="6ec84-118">若要了解头部和眼动跟踪设计概念的运行情况，请查看下面的设计 **全息影像 -** 头部跟踪和眼动跟踪视频演示。</span><span class="sxs-lookup"><span data-stu-id="6ec84-118">If you'd like to see Head and Eye Tracking design concepts in action, check out our **Designing Holograms - Head Tracking and Eye Tracking** video demo below.</span></span> <span data-ttu-id="6ec84-119">完成后，请继续详细了解特定主题。</span><span class="sxs-lookup"><span data-stu-id="6ec84-119">When you've finished, continue on for a more detailed dive into specific topics.</span></span>

> [!VIDEO https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Microsofts-Designing-Holograms-Head-Tracking-and-Eye-Tracking-Chapter/player]

<span data-ttu-id="6ec84-120">*此视频取自"设计全息影像"HoloLens 2应用。在此处下载并享受完整 [体验](https://aka.ms/dhapp)。*</span><span class="sxs-lookup"><span data-stu-id="6ec84-120">*This video was taken from the "Designing Holograms" HoloLens 2 app. Download and enjoy the full experience [here](https://aka.ms/dhapp).*</span></span>

## <a name="calibration"></a><span data-ttu-id="6ec84-121">校准</span><span class="sxs-lookup"><span data-stu-id="6ec84-121">Calibration</span></span> 

<span data-ttu-id="6ec84-122">若要准确运行眼动跟踪，每个用户都需要进行眼动跟踪用户校准[](/hololens/hololens-calibration)，用户必须查看一组全息目标。</span><span class="sxs-lookup"><span data-stu-id="6ec84-122">For eye tracking to work accurately, each user is required to go through an [eye tracking user calibration](/hololens/hololens-calibration) for which the user has to look at a set of holographic targets.</span></span> <span data-ttu-id="6ec84-123">这样，设备可以调整系统，为用户提供更舒适、更高质量的观看体验，并确保同时进行准确的眼动跟踪。</span><span class="sxs-lookup"><span data-stu-id="6ec84-123">This allows the device to adjust the system for a more comfortable and higher quality viewing experience for the user and to ensure accurate eye tracking at the same time.</span></span> 

<span data-ttu-id="6ec84-124">眼动跟踪应该适用于大多数用户，但在极少数情况下，用户无法成功校准。</span><span class="sxs-lookup"><span data-stu-id="6ec84-124">Eye tracking should work for most users, but there are rare cases in which a user can't calibrate successfully.</span></span> <span data-ttu-id="6ec84-125">校准可能会由于各种原因失败，包括但不限于：</span><span class="sxs-lookup"><span data-stu-id="6ec84-125">Calibration might fail for various reasons, including but not limited to:</span></span> 
* <span data-ttu-id="6ec84-126">用户以前选择退出校准过程</span><span class="sxs-lookup"><span data-stu-id="6ec84-126">The user previously opted out of the calibration process</span></span>
* <span data-ttu-id="6ec84-127">用户发散了注意力，没有遵循校准目标</span><span class="sxs-lookup"><span data-stu-id="6ec84-127">The user got distracted and didn't follow the calibration targets</span></span>
* <span data-ttu-id="6ec84-128">用户具有某些类型的接触镜和眼镜，系统尚不支持这些</span><span class="sxs-lookup"><span data-stu-id="6ec84-128">The user has certain types of contact lenses and glasses, which the system doesn't yet support</span></span> 
* <span data-ttu-id="6ec84-129">用户有一定的眼部眼部、眼部条件或眼部疾病，系统尚不支持这些</span><span class="sxs-lookup"><span data-stu-id="6ec84-129">The user has certain eye physiology, eye conditions or had eye surgery, which the system doesn't yet support</span></span>  
* <span data-ttu-id="6ec84-130">外部因素会阻止可靠的眼动跟踪，例如 HoloLens 视口或眼镜上的闪烁、密集直接吸收，以及眼前发造成的遮挡</span><span class="sxs-lookup"><span data-stu-id="6ec84-130">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight, and occlusions due to hair in front of the eyes</span></span>

<span data-ttu-id="6ec84-131">对于无法成功校准眼动跟踪数据的用户，开发人员 (提供足够的支持) 。</span><span class="sxs-lookup"><span data-stu-id="6ec84-131">Developers should make sure to provide adequate support for users for whom eye tracking data may not be available (who aren't able to calibrate successfully).</span></span> <span data-ttu-id="6ec84-132">我们在此页底部的 部分中提供了回退解决方案的建议。</span><span class="sxs-lookup"><span data-stu-id="6ec84-132">We have provided recommendations for fallback solutions in the section at the bottom of this page.</span></span> 

<span data-ttu-id="6ec84-133">若要详细了解校准以及如何确保顺畅的体验，请查看眼 [动跟踪用户校准](/hololens/hololens-calibration) 页。</span><span class="sxs-lookup"><span data-stu-id="6ec84-133">To learn more about the calibration and about how to ensure a smooth experience, check our [eye tracking user calibration](/hololens/hololens-calibration) page.</span></span>

<br>

## <a name="available-eye-tracking-data"></a><span data-ttu-id="6ec84-134">可用的眼动跟踪数据</span><span class="sxs-lookup"><span data-stu-id="6ec84-134">Available eye tracking data</span></span>

<span data-ttu-id="6ec84-135">在详细介绍眼睛凝视输入的特定用例之前，我们想要简要指出眼动跟踪 API HoloLens 2 [的功能](/uwp/api/windows.perception.people.eyespose) 。</span><span class="sxs-lookup"><span data-stu-id="6ec84-135">Before going into detail about specific use cases for eye-gaze input, we want to briefly point out the capabilities that the HoloLens 2 [Eye Tracking API](/uwp/api/windows.perception.people.eyespose) provides.</span></span> <span data-ttu-id="6ec84-136">开发人员可以访问 _30 Hz (约 30 F (PS) 30 Hz_ 的单个眼睛凝视射线和) 。</span><span class="sxs-lookup"><span data-stu-id="6ec84-136">Developers get access to a single eye-gaze ray (gaze origin and direction) at approximately _30 FPS (30 Hz)_.</span></span>
<span data-ttu-id="6ec84-137">若要详细了解如何访问眼动跟踪数据，请参阅开发人员指南，了解如何在 [DirectX](../develop/native/gaze-in-directx.md) 中使用眼睛凝视，在 Unity 中 [使用眼睛凝视](https://aka.ms/mrtk-eyes)。</span><span class="sxs-lookup"><span data-stu-id="6ec84-137">For more detailed information about how to access eye tracking data, refer to our developer guides for using [eye-gaze in DirectX](../develop/native/gaze-in-directx.md) and [eye-gaze in Unity](https://aka.ms/mrtk-eyes).</span></span>

<span data-ttu-id="6ec84-138">预测眼睛凝视大约位于实际目标周围 1.5 度（可视角度 (，请参阅下图) 。</span><span class="sxs-lookup"><span data-stu-id="6ec84-138">The predicted eye-gaze is approximately within 1.5 degrees in visual angle around the actual target (see the illustration below).</span></span> <span data-ttu-id="6ec84-139">由于预期会稍有不精确，开发人员应围绕此下限值规划一些边距 (例如，2.0-3.0 度可能会导致更舒适) 。</span><span class="sxs-lookup"><span data-stu-id="6ec84-139">As slight imprecisions are expected, developers should plan for some margin around this lower-bound value (for example, 2.0-3.0 degrees may result in a much more comfortable experience).</span></span> <span data-ttu-id="6ec84-140">下面将更详细地讨论如何处理小型目标的选择。</span><span class="sxs-lookup"><span data-stu-id="6ec84-140">We'll discuss how to address the selection of small targets in more detail below.</span></span> <span data-ttu-id="6ec84-141">要准确运行眼动跟踪，每个用户需要完成眼动跟踪用户校准。</span><span class="sxs-lookup"><span data-stu-id="6ec84-141">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="6ec84-142">![2 米远处的最佳目标大小](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="6ec84-142">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="6ec84-143">*2 米距离的最佳目标大小*</span><span class="sxs-lookup"><span data-stu-id="6ec84-143">*Optimal target size at a 2-meter distance*</span></span>

<br>

## <a name="use-cases"></a><span data-ttu-id="6ec84-144">用例</span><span class="sxs-lookup"><span data-stu-id="6ec84-144">Use cases</span></span>

<span data-ttu-id="6ec84-145">眼动跟踪可让应用程序实时跟踪用户正在注视的位置。</span><span class="sxs-lookup"><span data-stu-id="6ec84-145">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="6ec84-146">以下用例描述了在混合现实中通过眼动跟踪HoloLens 2交互。</span><span class="sxs-lookup"><span data-stu-id="6ec84-146">The following use cases describe some interactions that are possible with eye tracking on HoloLens 2 in mixed reality.</span></span>
<span data-ttu-id="6ec84-147">这些用例尚不是 Holographic Shell 体验的一 (，即启动应用程序时看到的HoloLens 2) 。</span><span class="sxs-lookup"><span data-stu-id="6ec84-147">These use cases aren't yet part of the Holographic Shell experience (that is, the interface that you see when you start up your HoloLens 2).</span></span>
<span data-ttu-id="6ec84-148">可以在混合现实工具包 中试用其中[](/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-main)一些功能，该工具包提供了几个有趣且功能强大的眼动跟踪示例，例如快速轻松地选择眼部支持的目标，以及根据用户看到的内容自动滚动文本。</span><span class="sxs-lookup"><span data-stu-id="6ec84-148">You can try some of them in the [Mixed Reality Toolkit](/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-main), which provides several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections, and automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="6ec84-149">用户意图</span><span class="sxs-lookup"><span data-stu-id="6ec84-149">User intent</span></span>

<span data-ttu-id="6ec84-150">有关用户查看位置和内容的信息为其他输入（如语音、手和控制器）提供了强大的上下文。</span><span class="sxs-lookup"><span data-stu-id="6ec84-150">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands, and controllers.</span></span>
<span data-ttu-id="6ec84-151">可在各种任务中使用此信息。</span><span class="sxs-lookup"><span data-stu-id="6ec84-151">This can be used for various tasks.</span></span>
<span data-ttu-id="6ec84-152">例如，通过查看全息影像并说"选择" (还可以看到凝视和提交) 或"放置此 *..."，* 然后查看用户想要 [](gaze-and-commit.md)放置全息影像的位置并说 *"...there"*。</span><span class="sxs-lookup"><span data-stu-id="6ec84-152">For example, this can range from quickly and effortlessly **targeting** across the scene by looking at a hologram and saying *"select"* (also see [gaze and commit](gaze-and-commit.md)) or *"put this..."*, then looking over to where the user wants to place the hologram and say *"...there"*.</span></span> <span data-ttu-id="6ec84-153">在[混合现实工具包 - 视线支持的目标选择](/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-target-selection)和[混合现实工具包 - 视线支持的目标定位](/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-positioning)中可以找到相关示例。</span><span class="sxs-lookup"><span data-stu-id="6ec84-153">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-target-selection) and [Mixed Reality Toolkit - Eye-supported Target Positioning](/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-positioning).</span></span>

<span data-ttu-id="6ec84-154">此外，用户意向的示例可能包括使用有关用户所查看内容的信息来增强与虚拟代理和交互式全息影像的交互。</span><span class="sxs-lookup"><span data-stu-id="6ec84-154">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="6ec84-155">例如，虚拟代理可能会根据当前查看的内容调整可用选项及其行为。</span><span class="sxs-lookup"><span data-stu-id="6ec84-155">For instance, virtual agents might adapt available options and their behavior, based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="6ec84-156">隐式操作</span><span class="sxs-lookup"><span data-stu-id="6ec84-156">Implicit actions</span></span>

<span data-ttu-id="6ec84-157">隐式操作的类别与用户意图密切相关。</span><span class="sxs-lookup"><span data-stu-id="6ec84-157">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="6ec84-158">其思路是，全息影像或用户界面元素以一种本能的方式做出反应，甚至不会像用户与系统交互一样，而是让系统和用户保持同步。例如， **基于眼睛凝** 视的自动滚动，用户可以读取长文本，一旦用户进入文本框底部，即可自动开始滚动，使用户保持在阅读流中，而无需举手。</span><span class="sxs-lookup"><span data-stu-id="6ec84-158">The idea is that holograms or user interface elements react in an instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user can read a long text, which automatically starts scrolling once the user gets to the bottom of the textbox to keep the user in the flow of reading, without lifting a finger.</span></span>  
<span data-ttu-id="6ec84-159">这一点的关键方面是滚动速度适应用户的阅读速度。</span><span class="sxs-lookup"><span data-stu-id="6ec84-159">A key aspect of this is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="6ec84-160">另一个示例 **是支持** 眼睛的缩放和平移，用户可以在其中感觉完全深入到自己所关注的地方。</span><span class="sxs-lookup"><span data-stu-id="6ec84-160">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she's focused on.</span></span> <span data-ttu-id="6ec84-161">可以通过语音或手动输入来控制触发和控制缩放速度，这一点对于为用户提供控制感，同时避免被过度控制非常重要。</span><span class="sxs-lookup"><span data-stu-id="6ec84-161">Triggering and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="6ec84-162">下面将更详细地讨论这些设计注意事项。</span><span class="sxs-lookup"><span data-stu-id="6ec84-162">We'll talk about these design considerations in more detail below.</span></span> <span data-ttu-id="6ec84-163">放大后，用户可以顺畅地跟随街道路线，使用眼睛凝视来探索自己附近的区域。</span><span class="sxs-lookup"><span data-stu-id="6ec84-163">Once zoomed in, the user can smoothly follow, for example, the course of a street to explore his or her neighborhood by using their eye-gaze.</span></span>
<span data-ttu-id="6ec84-164">[混合现实工具包 - 视线支持的导航](/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-navigation)示例中可以找到此类交互的演示。</span><span class="sxs-lookup"><span data-stu-id="6ec84-164">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-navigation) sample.</span></span>

<span data-ttu-id="6ec84-165">隐式操作的其他 _用例_ 可能包括：</span><span class="sxs-lookup"><span data-stu-id="6ec84-165">Other use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="6ec84-166">**智能通知：** 是否曾经因为通知弹出而感到麻烦？</span><span class="sxs-lookup"><span data-stu-id="6ec84-166">**Smart notifications:** Ever get annoyed by notifications popping up right where you're looking?</span></span> <span data-ttu-id="6ec84-167">考虑到用户正在关注哪些方面，可以通过从用户当前正在其中接收的通知进行偏移来改善此体验。</span><span class="sxs-lookup"><span data-stu-id="6ec84-167">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="6ec84-168">这会限制干扰，在用户完成阅读后自动消除这些干扰。</span><span class="sxs-lookup"><span data-stu-id="6ec84-168">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="6ec84-169">**全息影像：** 在被放大时做出小反应的全息影像。</span><span class="sxs-lookup"><span data-stu-id="6ec84-169">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="6ec84-170">这可以从略微闪烁的 UI 元素、一种缓慢闪烁的花色，到开始回过头看用户并缩小其尾部的虚拟狗。</span><span class="sxs-lookup"><span data-stu-id="6ec84-170">This can range from slightly glowing UI elements, a slowly blooming flower to a virtual dog starting to look back at the user and wagging its tail.</span></span> <span data-ttu-id="6ec84-171">这种交互可能在应用程序中提供有趣的连接感和满意度。</span><span class="sxs-lookup"><span data-stu-id="6ec84-171">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="6ec84-172">注意力跟踪</span><span class="sxs-lookup"><span data-stu-id="6ec84-172">Attention tracking</span></span>

<span data-ttu-id="6ec84-173">有关用户查看位置或内容的信息可能是一个非常强大的工具。</span><span class="sxs-lookup"><span data-stu-id="6ec84-173">Information on where or what users look at can be an immensely powerful tool.</span></span> <span data-ttu-id="6ec84-174">它可以帮助评估设计的可用性，并确定工作流中的问题，使其更高效。</span><span class="sxs-lookup"><span data-stu-id="6ec84-174">It can help assess usability of designs and identify problems in workflows to make them more efficient.</span></span>
<span data-ttu-id="6ec84-175">眼动跟踪可视化和分析是各种应用程序领域的常见做法。</span><span class="sxs-lookup"><span data-stu-id="6ec84-175">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="6ec84-176">借助HoloLens 2，我们为这种理解提供了一个新维度，因为 3D 全息影像可以放置在实际上下文中并相应地进行评估。</span><span class="sxs-lookup"><span data-stu-id="6ec84-176">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="6ec84-177">混合 [现实工具包](/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-main) 提供了日志记录和加载眼动跟踪数据以及如何可视化它们的基本示例。</span><span class="sxs-lookup"><span data-stu-id="6ec84-177">The [Mixed Reality Toolkit](/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-main) provides basic examples for logging and loading eye tracking data and how to visualize them.</span></span>
<span data-ttu-id="6ec84-178">Microsoft 致力于促进创新，同时确保用户在眼动跟踪信息的使用方式方面获得明智的透明体验。</span><span class="sxs-lookup"><span data-stu-id="6ec84-178">Microsoft is dedicated to facilitating innovation while ensuring that users have an informed and transparent experience with how their eye tracking information is used.</span></span>  <span data-ttu-id="6ec84-179">我们将与开发人员和 UX 团队合作，为第三方提供指导，以确保体验以用户为中心。</span><span class="sxs-lookup"><span data-stu-id="6ec84-179">We'll work with our developers and UX teams to provide guidance for third parties to ensure that experiences are centered around the user.</span></span>  

<span data-ttu-id="6ec84-180">此领域的其他应用场景包括：</span><span class="sxs-lookup"><span data-stu-id="6ec84-180">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="6ec84-181">**远程眼睛凝视可视化：** 远程眼睛凝视可视化效果：可视化远程协作者正在查看的内容，以便提供即时反馈，促进更准确的信息处理。</span><span class="sxs-lookup"><span data-stu-id="6ec84-181">**Remote eye-gaze visualization:** Remote eye-gaze visualizations: Visualize what remote collaborators are looking at, to be able to provide immediate feedback and facilitate more accurate information processing.</span></span>
-   <span data-ttu-id="6ec84-182">**用户研究：** 关注跟踪可以帮助研究人员深入了解用户如何感知和接触自然环境，而不会干扰，以设计更自然的人机交互。</span><span class="sxs-lookup"><span data-stu-id="6ec84-182">**User research studies:** Attention tracking can help researchers get more insights into how users perceive and engage with the natural environment, without interfering, to design more instinctual human-computer-interactions.</span></span> <span data-ttu-id="6ec84-183">眼动跟踪可以提供参与者未直接表达的信息，否则研究人员可能很容易错过这些信息。</span><span class="sxs-lookup"><span data-stu-id="6ec84-183">Eye tracking can provide information that is not directly articulated by participants in the study, which otherwise might be easily missed by the researcher.</span></span> 
-   <span data-ttu-id="6ec84-184">**训练和性能监视：** 通过更有效地识别执行流中的瓶颈来练习和优化任务的执行。</span><span class="sxs-lookup"><span data-stu-id="6ec84-184">**Training and performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span> <span data-ttu-id="6ec84-185">眼动跟踪可以提供自然、实时和目标信息，以帮助改进工作区中的培训、生产力和安全性。</span><span class="sxs-lookup"><span data-stu-id="6ec84-185">Eye tracking can provide natural, real-time, and objective information to help improve training, productivity, and safety in the workplace.</span></span> 
-   <span data-ttu-id="6ec84-186">**设计评估、营销和使用者研究：** 眼动跟踪使商业公司能够在实际环境中执行营销和使用者研究，或分析吸引用户注意以改进产品或空间设计的问题。</span><span class="sxs-lookup"><span data-stu-id="6ec84-186">**Design evaluations, marketing, and consumer research:** Eye tracking enables commercial companies to perform marketing and consumer studies in real-world environments or analyze what captures a user’s attention to improve product or space design.</span></span> 

### <a name="other-use-cases"></a><span data-ttu-id="6ec84-187">其他用例</span><span class="sxs-lookup"><span data-stu-id="6ec84-187">Other use cases</span></span>

- <span data-ttu-id="6ec84-188">**Gaming:** Ever wanted to have superpowers?</span><span class="sxs-lookup"><span data-stu-id="6ec84-188">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="6ec84-189">机会来了！</span><span class="sxs-lookup"><span data-stu-id="6ec84-189">Here's your chance!</span></span> <span data-ttu-id="6ec84-190">可以通过凝视全息影像来放大全息影像。</span><span class="sxs-lookup"><span data-stu-id="6ec84-190">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="6ec84-191">从眼睛中发射射线 - 在[RoboRaid 中试用，HoloLens 2。](https://www.microsoft.com/p/roboraid/9nblggh5fv3j)</span><span class="sxs-lookup"><span data-stu-id="6ec84-191">Shoot laser beams from your eyes - try it out in [RoboRaid for HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j).</span></span>
<span data-ttu-id="6ec84-192">将它们变成块或冻结它们。</span><span class="sxs-lookup"><span data-stu-id="6ec84-192">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="6ec84-193">使用 X 光透视来扫描建筑物。</span><span class="sxs-lookup"><span data-stu-id="6ec84-193">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="6ec84-194">没有做不到，只有想不到！</span><span class="sxs-lookup"><span data-stu-id="6ec84-194">Your imagination is the limit!</span></span>
<span data-ttu-id="6ec84-195">不过，请注意不要使用户占上用场 - 若要了解更多内容，请查看我们基于眼睛凝视的 [输入设计准则](eye-gaze-interaction.md)。</span><span class="sxs-lookup"><span data-stu-id="6ec84-195">Beware of not overwhelming the user though - to find out more, check out our [eye-gaze-based input design guidelines](eye-gaze-interaction.md).</span></span>

- <span data-ttu-id="6ec84-196">**表达式头像：** 眼动跟踪通过使用实时眼动跟踪数据对头像眼睛进行动画处理，以指示用户正在查看的内容，帮助获得更具表现力 3D 头像。</span><span class="sxs-lookup"><span data-stu-id="6ec84-196">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking data to animate the avatar's eyes that indicate what the user is looking at.</span></span> 

- <span data-ttu-id="6ec84-197">**文本条目：** 眼动跟踪可以用作低工作量文本输入的替代方法，尤其是在语音或手不方便使用时。</span><span class="sxs-lookup"><span data-stu-id="6ec84-197">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 

<br>

## <a name="using-eye-gaze-for-interaction"></a><span data-ttu-id="6ec84-198">使用眼睛凝视进行交互</span><span class="sxs-lookup"><span data-stu-id="6ec84-198">Using eye-gaze for interaction</span></span>

<span data-ttu-id="6ec84-199">构建利用快速移动眼睛定位的交互可能比较困难。</span><span class="sxs-lookup"><span data-stu-id="6ec84-199">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span>
<span data-ttu-id="6ec84-200">一方面，眼睛移动得非常快，因此你需要小心如何使用眼睛凝视输入，因为否则用户可能会发现体验令人难以承受或分散注意力。</span><span class="sxs-lookup"><span data-stu-id="6ec84-200">On the one hand, the eyes move so fast that you need to be careful on how to use eye-gaze input, because otherwise users may find the experience overwhelming or distracting.</span></span> <span data-ttu-id="6ec84-201">另一方面，还可以创建真正激发用户体验的体验！</span><span class="sxs-lookup"><span data-stu-id="6ec84-201">On the other hand, you can also create truly magical experiences that will excite your users!</span></span> <span data-ttu-id="6ec84-202">为了帮助你，请查看有关重要优势、挑战的概述，以及针对交互的眼睛凝视 [的设计建议](eye-gaze-interaction.md)。</span><span class="sxs-lookup"><span data-stu-id="6ec84-202">To help you, check out our overview of key advantages, challenges, and design recommendations for [eye-gaze for interaction](eye-gaze-interaction.md).</span></span> 
 
## <a name="fallback-solutions-when-eye-tracking-isnt-available"></a><span data-ttu-id="6ec84-203">眼动跟踪不可用时回退解决方案</span><span class="sxs-lookup"><span data-stu-id="6ec84-203">Fallback solutions when eye tracking isn't available</span></span>

<span data-ttu-id="6ec84-204">在极少数情况下，眼动跟踪数据可能不可用。</span><span class="sxs-lookup"><span data-stu-id="6ec84-204">In rare cases, eye tracking data might not be available.</span></span>
<span data-ttu-id="6ec84-205">原因可能是下面列出了最常见的原因：</span><span class="sxs-lookup"><span data-stu-id="6ec84-205">This can be because of different reasons from which the most common are listed below:</span></span>
* <span data-ttu-id="6ec84-206">系统无法 [校准用户](/hololens/hololens-calibration)。</span><span class="sxs-lookup"><span data-stu-id="6ec84-206">The system failed to [calibrate the user](/hololens/hololens-calibration).</span></span>
* <span data-ttu-id="6ec84-207">用户跳过了 [校准](/hololens/hololens-calibration)。</span><span class="sxs-lookup"><span data-stu-id="6ec84-207">The user skipped the [calibration](/hololens/hololens-calibration).</span></span>   
* <span data-ttu-id="6ec84-208">用户已校准，但决定不向应用授予使用眼动跟踪数据的权限。</span><span class="sxs-lookup"><span data-stu-id="6ec84-208">The user is calibrated, but decided to not give permission to your app to use their eye tracking data.</span></span>    
* <span data-ttu-id="6ec84-209">用户具有唯一的眼镜或系统尚不支持的某种眼部条件。</span><span class="sxs-lookup"><span data-stu-id="6ec84-209">The user has unique eyeglasses or some eye condition that the system doesn't yet support.</span></span> 
* <span data-ttu-id="6ec84-210">外部因素会阻止可靠的眼动跟踪，例如 HoloLens 视口或眼镜上的闪烁、密集直接吸收，以及由于眼睛前面有发而遮挡。</span><span class="sxs-lookup"><span data-stu-id="6ec84-210">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight, and occlusions because of hair in front of the eyes.</span></span>

<span data-ttu-id="6ec84-211">开发人员应确保为这些用户提供适当的回退支持。</span><span class="sxs-lookup"><span data-stu-id="6ec84-211">Developers should ensure that there's appropriate fallback support for these users.</span></span> <span data-ttu-id="6ec84-212">在 [DirectX 中的眼动跟踪页上](../develop/native/gaze-in-directx.md#fallback-when-eye-tracking-isnt-available) ，我们介绍了检测眼动跟踪数据是否可用所需的 API。</span><span class="sxs-lookup"><span data-stu-id="6ec84-212">On the [Eye Tracking in DirectX](../develop/native/gaze-in-directx.md#fallback-when-eye-tracking-isnt-available) page, we explain the APIs required to detect whether eye tracking data is available.</span></span> 

<span data-ttu-id="6ec84-213">虽然一些用户可能有意决定撤销，但访问其眼动跟踪数据，并且对于不提供眼动跟踪数据访问权限的隐私的牺牲性用户体验是正常，但在某些情况下，这可能是无意的。</span><span class="sxs-lookup"><span data-stu-id="6ec84-213">While some users may have consciously decided to revoke,  access to their eye tracking data and are ok with the trade-off of an inferior user experience to the privacy of not providing access to their eye tracking data, in some cases this may be unintentional.</span></span> <span data-ttu-id="6ec84-214">如果应用使用眼动跟踪，并且这是体验的重要组成部分，我们建议清楚地向用户传达这一信息。</span><span class="sxs-lookup"><span data-stu-id="6ec84-214">If your app uses eye tracking, and this is an important part of the experience, we recommend clearly communicating this to the user.</span></span>   

<span data-ttu-id="6ec84-215">请告知用户眼动跟踪为何对应用程序至关重要 (甚至列出一些增强的功能) 以体验应用程序的全部潜力，可帮助用户更好地了解他们放弃的功能。</span><span class="sxs-lookup"><span data-stu-id="6ec84-215">Kindly informing the user why eye tracking is critical for your application (maybe even listing some enhanced features) to experience the full potential of your application, can help the user to better understand what they're giving up.</span></span> <span data-ttu-id="6ec84-216">帮助用户根据上述检查确定眼动跟踪 (的原因，并提供一) 建议以快速排查潜在问题。</span><span class="sxs-lookup"><span data-stu-id="6ec84-216">Help the user identify why eye tracking may not be working (based on the above checks) and offer some suggestions to quickly troubleshoot potential issues.</span></span> 

<span data-ttu-id="6ec84-217">例如，如果检测到系统支持眼动跟踪，则用户已校准，甚至已授予其权限，但尚未收到任何眼动跟踪数据，则这可能指向一些其他问题，例如闪烁或眼睛被遮挡。</span><span class="sxs-lookup"><span data-stu-id="6ec84-217">For example, if you can detect that the system supports eye tracking, the user is calibrated and has even given their permission, yet no eye tracking data is received, then this may point to some other issues such as smudges or the eyes being occluded.</span></span> 

<span data-ttu-id="6ec84-218">在极少数情况下，眼动跟踪可能无法工作的用户。</span><span class="sxs-lookup"><span data-stu-id="6ec84-218">There are rare cases of users for whom eye tracking may not work.</span></span> <span data-ttu-id="6ec84-219">因此，请通过允许关闭甚至禁用在应用中启用眼动跟踪的提醒来消除这一点。</span><span class="sxs-lookup"><span data-stu-id="6ec84-219">Hence, please be respectful of that by allowing to dismiss or even disable reminders for enabling eye tracking in your app.</span></span>

### <a name="fall-back-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a><span data-ttu-id="6ec84-220">回退使用眼睛凝视作为主要输入指针的应用</span><span class="sxs-lookup"><span data-stu-id="6ec84-220">Fall back for apps using eye-gaze as a primary input pointer</span></span>

<span data-ttu-id="6ec84-221">如果应用使用眼睛凝视作为指针输入，以快速选择场景中的全息影像，但眼动跟踪数据不可用，我们建议返回到头部凝视并开始显示头部凝视光标。</span><span class="sxs-lookup"><span data-stu-id="6ec84-221">If your app uses eye-gaze as a pointer input to quickly select holograms across the scene, yet eye tracking data is unavailable, we recommend falling back to head-gaze and start showing the head-gaze cursor.</span></span> <span data-ttu-id="6ec84-222">建议使用超时值 (例如 500–1500 毫秒) 确定是否切换。</span><span class="sxs-lookup"><span data-stu-id="6ec84-222">We recommend using a timeout (for example, 500–1500 ms) to determine whether to switch or not.</span></span> <span data-ttu-id="6ec84-223">此操作可防止每次系统由于快速眼睛运动或闪烁而短暂丢失跟踪时出现光标。</span><span class="sxs-lookup"><span data-stu-id="6ec84-223">This action prevents cursors from appearing every time the system may briefly lose tracking because of fast eye motions or winks and blinks.</span></span> <span data-ttu-id="6ec84-224">如果你是 Unity 开发人员，混合现实工具包中已处理了头部凝视的自动回退。</span><span class="sxs-lookup"><span data-stu-id="6ec84-224">If you're a Unity developer, the automatic fallback to head-gaze is already handled in the Mixed Reality Toolkit.</span></span> <span data-ttu-id="6ec84-225">如果你是 DirectX 开发人员，则需要自己处理此开关。</span><span class="sxs-lookup"><span data-stu-id="6ec84-225">If you're a DirectX developer, you need to handle this switch yourself.</span></span>

### <a name="fall-back-for-other-eye-tracking-specific-applications"></a><span data-ttu-id="6ec84-226">回退到其他特定于眼动跟踪的应用程序</span><span class="sxs-lookup"><span data-stu-id="6ec84-226">Fall back for other eye-tracking-specific applications</span></span>

<span data-ttu-id="6ec84-227">应用可能会以专门针对眼睛定制的独特方式使用眼睛凝视。</span><span class="sxs-lookup"><span data-stu-id="6ec84-227">Your app may use eye-gaze in a unique way that is tailored specifically to the eyes.</span></span> <span data-ttu-id="6ec84-228">例如，对头像眼睛进行动画处理，或对基于眼睛的注意热度地图进行动画处理，这依赖于有关视觉注意的精确信息。</span><span class="sxs-lookup"><span data-stu-id="6ec84-228">For example, animating an avatar’s eyes or for eye-based attention heatmaps relying on precise information about visual attention.</span></span> <span data-ttu-id="6ec84-229">在这种情况下，没有明确的回退。</span><span class="sxs-lookup"><span data-stu-id="6ec84-229">In this case, there's no clear fallback.</span></span> <span data-ttu-id="6ec84-230">如果眼动跟踪不可用，可能需要禁用这些功能。</span><span class="sxs-lookup"><span data-stu-id="6ec84-230">If eye tracking isn't available, these capabilities may need to be disabled.</span></span>
<span data-ttu-id="6ec84-231">同样，建议向可能不知道该功能不工作的用户明确传达此信息。</span><span class="sxs-lookup"><span data-stu-id="6ec84-231">Again, we recommend to clearly communicate this to the user who may be unaware that the capability isn't working.</span></span>

<br>

<span data-ttu-id="6ec84-232">本页希望能够提供一个很好的概述，让你开始了解眼动跟踪和眼睛凝视输入HoloLens 2。</span><span class="sxs-lookup"><span data-stu-id="6ec84-232">This page has hopefully provided you with a good overview to get you started understanding the role of eye tracking and eye-gaze input for HoloLens 2.</span></span> <span data-ttu-id="6ec84-233">若要开始开发，请查看有关眼睛凝视与全息影像交互[](eye-gaze-interaction.md)[、Unity](https://aka.ms/mrtk-eyes)中眼睛凝视和 DirectX 中眼睛[凝视的作用的信息](../develop/native/gaze-in-directx.md)。</span><span class="sxs-lookup"><span data-stu-id="6ec84-233">To get started developing, check out our information on the role of [eye-gaze for interacting with holograms](eye-gaze-interaction.md), [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](../develop/native/gaze-in-directx.md).</span></span>

## <a name="see-also"></a><span data-ttu-id="6ec84-234">另请参阅</span><span class="sxs-lookup"><span data-stu-id="6ec84-234">See also</span></span>

* [<span data-ttu-id="6ec84-235">校准</span><span class="sxs-lookup"><span data-stu-id="6ec84-235">Calibration</span></span>](/hololens/hololens-calibration)
* [<span data-ttu-id="6ec84-236">舒适</span><span class="sxs-lookup"><span data-stu-id="6ec84-236">Comfort</span></span>](comfort.md)
* [<span data-ttu-id="6ec84-237">基于眼睛凝视的交互</span><span class="sxs-lookup"><span data-stu-id="6ec84-237">Eye-gaze-based interaction</span></span>](eye-gaze-interaction.md)
* [<span data-ttu-id="6ec84-238">DirectX 中的眼睛凝视</span><span class="sxs-lookup"><span data-stu-id="6ec84-238">Eye-gaze in DirectX</span></span>](../develop/native/gaze-in-directx.md)
* [<span data-ttu-id="6ec84-239">Unity 中的眼睛凝视 (混合现实工具包) </span><span class="sxs-lookup"><span data-stu-id="6ec84-239">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="6ec84-240">凝视和提交</span><span class="sxs-lookup"><span data-stu-id="6ec84-240">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="6ec84-241">语音输入</span><span class="sxs-lookup"><span data-stu-id="6ec84-241">Voice input</span></span>](../out-of-scope/voice-design.md)
