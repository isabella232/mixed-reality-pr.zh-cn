---
title: 基于眼睛凝视的交互
description: 了解 HoloLens 2 上的眼睛和目视交互，以及新级别的上下文和人工理解（如果在全息体验中获得）。
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: 目视跟踪，混合现实，输入，眼睛，混合现实耳机，windows Mixed reality 耳机，虚拟现实耳机，HoloLens，MRTK，混合现实工具包，设计，交互
ms.openlocfilehash: 3067f5533dbe70d4decb6b5cf94a3f1c5029115a
ms.sourcegitcommit: 72970dbe6674e28c250f741e50a44a238bb162d4
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 06/25/2021
ms.locfileid: "112906863"
---
# <a name="eye-gaze-based-interaction-on-hololens-2"></a><span data-ttu-id="9e401-104">HoloLens 2 上基于目视的目视交互</span><span class="sxs-lookup"><span data-stu-id="9e401-104">Eye-gaze-based interaction on HoloLens 2</span></span>

![MRTK 中的眼睛跟踪演示](images/mrtk_et_scenemenu.jpg)

<span data-ttu-id="9e401-106">HoloLens 2 上令人兴奋的新功能之一是目视跟踪。</span><span class="sxs-lookup"><span data-stu-id="9e401-106">One of our exciting new capabilities on HoloLens 2 is eye tracking.</span></span> <span data-ttu-id="9e401-107">在我们的 " [HoloLens 2](eye-tracking.md) " 页面上，我们提到了对每个用户进行 [校准](/hololens/hololens-calibration)的需求，提供了一些开发人员指南和突出跟踪的突出显示用例。</span><span class="sxs-lookup"><span data-stu-id="9e401-107">On our [Eye tracking on HoloLens 2](eye-tracking.md) page, we mentioned the need for each user to go through a [Calibration](/hololens/hololens-calibration), provided some developer guidance, and highlighted use cases for eye tracking.</span></span> <span data-ttu-id="9e401-108">目视输入仍是一种新类型的用户输入，有很多东西需要学习。</span><span class="sxs-lookup"><span data-stu-id="9e401-108">Eye-gaze input is still a new type of user input and there's a lot to learn.</span></span> 

<span data-ttu-id="9e401-109">尽管眼睛输入仅在板块的用户界面 (在您启动 HoloLens 2) 时看到的用户界面，但多个应用程序（例如 ["Hololens"](https://www.microsoft.com/p/mr-playground/9nb31lh723s2)）的情况下显示了很好的示例，其中展示了目视输入如何添加到您的全息体验的神奇之处。</span><span class="sxs-lookup"><span data-stu-id="9e401-109">While eye-gaze input is only used subtly in our Holographic Shell experience (the user interface that you see when you start your HoloLens 2), several apps, such as the ["HoloLens Playground"](https://www.microsoft.com/p/mr-playground/9nb31lh723s2), showcase great examples on how eye-gaze input can add to the magic of your holographic experience.</span></span>
<span data-ttu-id="9e401-110">在此页上，我们将讨论集成眼睛输入以与全息版应用程序进行交互的设计注意事项。</span><span class="sxs-lookup"><span data-stu-id="9e401-110">On this page, we discuss design considerations for integrating eye-gaze input to interact with your holographic applications.</span></span>

<span data-ttu-id="9e401-111">你将了解关键的优点，还会遇到一些与目视输入相关的独特挑战。</span><span class="sxs-lookup"><span data-stu-id="9e401-111">You'll learn about key advantages and also unique challenges that come with eye-gaze input.</span></span> <span data-ttu-id="9e401-112">根据这些建议，我们提供了若干设计建议，以帮助你创建满足目视支持的用户界面。</span><span class="sxs-lookup"><span data-stu-id="9e401-112">Based on these, we provide several design recommendations to help you create satisfying eye-gaze-supported user interfaces.</span></span> 

## <a name="device-support"></a><span data-ttu-id="9e401-113">设备支持</span><span class="sxs-lookup"><span data-stu-id="9e401-113">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="9e401-114"><strong>功能</strong></span><span class="sxs-lookup"><span data-stu-id="9e401-114"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="9e401-115"><a href="/hololens/hololens1-hardware"><strong>HoloLens（第 1 代）</strong></a></span><span class="sxs-lookup"><span data-stu-id="9e401-115"><a href="/hololens/hololens1-hardware"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="9e401-116"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="9e401-116"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="9e401-117"><a href="../discover/immersive-headset-hardware-details.md"><strong>沉浸式头戴显示设备</strong></a></span><span class="sxs-lookup"><span data-stu-id="9e401-117"><a href="../discover/immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="9e401-118">眼睛-注视</span><span class="sxs-lookup"><span data-stu-id="9e401-118">Eye-gaze</span></span></td>
     <td>❌</td>
     <td><span data-ttu-id="9e401-119">✔️</span><span class="sxs-lookup"><span data-stu-id="9e401-119">✔️</span></span></td>
     <td>❌</td>
</tr>
</table>

## <a name="head-and-eye-tracking-design-concepts-demo"></a><span data-ttu-id="9e401-120">标题和眼睛跟踪设计概念演示</span><span class="sxs-lookup"><span data-stu-id="9e401-120">Head and eye tracking design concepts demo</span></span>

<span data-ttu-id="9e401-121">若要查看标题和目视跟踪的设计概念，请参阅下面的 **设计全息影像-打印头跟踪和眼睛跟踪** 视频演示。</span><span class="sxs-lookup"><span data-stu-id="9e401-121">If you'd like to see Head and Eye Tracking design concepts in action, check out our **Designing Holograms - Head Tracking and Eye Tracking** video demo below.</span></span> <span data-ttu-id="9e401-122">完成后，请继续详细了解特定主题。</span><span class="sxs-lookup"><span data-stu-id="9e401-122">When you've finished, continue on for a more detailed dive into specific topics.</span></span>

> [!VIDEO https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Microsofts-Designing-Holograms-Head-Tracking-and-Eye-Tracking-Chapter/player]

<span data-ttu-id="9e401-123">*此视频取自 "设计全息影像" HoloLens 2 应用。下载并在 [此处](https://aka.ms/dhapp)享受完全体验。*</span><span class="sxs-lookup"><span data-stu-id="9e401-123">*This video was taken from the "Designing Holograms" HoloLens 2 app. Download and enjoy the full experience [here](https://aka.ms/dhapp).*</span></span>

## <a name="eye-gaze-input-design-guidelines"></a><span data-ttu-id="9e401-124">目视输入设计准则</span><span class="sxs-lookup"><span data-stu-id="9e401-124">Eye-gaze input design guidelines</span></span>

<span data-ttu-id="9e401-125">构建充分利用快速移动目视目标的交互可能会很困难。</span><span class="sxs-lookup"><span data-stu-id="9e401-125">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span> <span data-ttu-id="9e401-126">在本部分中，我们总结了在设计应用程序时要考虑的主要优点和挑战。</span><span class="sxs-lookup"><span data-stu-id="9e401-126">In this section, we summarize the key advantages and challenges to consider when designing your application.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="9e401-127">目视输入的优点</span><span class="sxs-lookup"><span data-stu-id="9e401-127">Benefits of eye-gaze input</span></span>

- <span data-ttu-id="9e401-128">**高速指向。**</span><span class="sxs-lookup"><span data-stu-id="9e401-128">**High speed pointing.**</span></span> <span data-ttu-id="9e401-129">眼睛判断力是人为身体最快的响应判断力。</span><span class="sxs-lookup"><span data-stu-id="9e401-129">The eye muscle is the fastest reacting muscle in the human body.</span></span> 

- <span data-ttu-id="9e401-130">**不费力。**</span><span class="sxs-lookup"><span data-stu-id="9e401-130">**Low effort.**</span></span> <span data-ttu-id="9e401-131">几乎没有任何身体动作。</span><span class="sxs-lookup"><span data-stu-id="9e401-131">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="9e401-132">**隐含性。**</span><span class="sxs-lookup"><span data-stu-id="9e401-132">**Implicitness.**</span></span> <span data-ttu-id="9e401-133">用户通常会将其描述为 "构思阅读"，有关用户的目视变动的信息使系统可以知道用户打算参与哪个目标。</span><span class="sxs-lookup"><span data-stu-id="9e401-133">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage.</span></span> 

- <span data-ttu-id="9e401-134">**备选的输入通道。**</span><span class="sxs-lookup"><span data-stu-id="9e401-134">**Alternative input channel.**</span></span> <span data-ttu-id="9e401-135">眼睛可为用户提供强大的支持输入，并根据用户的手眼协调从用户的经验中生成。</span><span class="sxs-lookup"><span data-stu-id="9e401-135">Eye-gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="9e401-136">**视觉注意力。**</span><span class="sxs-lookup"><span data-stu-id="9e401-136">**Visual attention.**</span></span> <span data-ttu-id="9e401-137">另一个重要的优点是可以推断出用户正在关注的内容。</span><span class="sxs-lookup"><span data-stu-id="9e401-137">Another important benefit is the possibility to infer what a user is paying attention to.</span></span> <span data-ttu-id="9e401-138">这可以帮助不同的应用程序领域，从更有效地评估不同设计，到协助的用户界面，增加了社交提示以进行远程通信。</span><span class="sxs-lookup"><span data-stu-id="9e401-138">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter user interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="9e401-139">简而言之，使用眼睛眼睛作为输入可提供快速且简单的上下文输入信号。</span><span class="sxs-lookup"><span data-stu-id="9e401-139">In a nutshell, using eye-gaze as an input offers a fast and effortless contextual input signal.</span></span> <span data-ttu-id="9e401-140">与其他输入（如 *语音* 和 *手动* 输入）结合在一起时，此功能非常强大，可以确认用户的意图。</span><span class="sxs-lookup"><span data-stu-id="9e401-140">This is powerful when combined with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="9e401-141">眼睛为输入的挑战</span><span class="sxs-lookup"><span data-stu-id="9e401-141">Challenges of eye-gaze as an input</span></span>

<span data-ttu-id="9e401-142">虽然眼睛可用于创建符合用户体验的用户体验，但使您感到 superhero，但也必须知道这种情况并不好。</span><span class="sxs-lookup"><span data-stu-id="9e401-142">While eye-gaze can be used to create satisfying user experiences, which make you feel like a superhero, it's also important to know what it isn't good at to appropriately account for this.</span></span> <span data-ttu-id="9e401-143">下面的列表讨论了一些需要考虑的问题，以及如何解决这些 *问题* ，以便使用目视的输入：</span><span class="sxs-lookup"><span data-stu-id="9e401-143">The following list discusses some *challenges* to consider and how to address them when working with eye-gaze input:</span></span> 

- <span data-ttu-id="9e401-144">**眼睛为 "始终打开"** 打开眼睛护盖后，眼睛开始 fixating 环境中的东西。</span><span class="sxs-lookup"><span data-stu-id="9e401-144">**Your eye-gaze is "always on"** The moment you open your eye lids, your eyes start fixating on things in the environment.</span></span> <span data-ttu-id="9e401-145">对每个外观作出反应并意外发出操作，因为您查看的内容太长，会导致 unsatisfying 的体验。</span><span class="sxs-lookup"><span data-stu-id="9e401-145">Reacting to every look you make and accidentally issuing actions, because you looked at something for too long, would result in an unsatisfying experience.</span></span>
<span data-ttu-id="9e401-146">建议将眼睛与 *声音命令*、手势、*按钮单击* 或扩展停留结合 *起来，以* 触发选择目标 (有关详细信息，请参阅 [眼睛和提交](gaze-and-commit-eyes.md)) 。</span><span class="sxs-lookup"><span data-stu-id="9e401-146">We recommend combining eye-gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target (for more information, see [eye-gaze and commit](gaze-and-commit-eyes.md)).</span></span>
<span data-ttu-id="9e401-147">此解决方案还允许使用一种模式，在该模式下，用户可以自由地查找，而不会因触发某些事情而 involuntarily。</span><span class="sxs-lookup"><span data-stu-id="9e401-147">This solution also allows for a mode in which the user can freely look around without being overwhelmed by involuntarily triggering something.</span></span> <span data-ttu-id="9e401-148">当查看目标时设计视觉对象和听觉反馈时，还应考虑此问题。</span><span class="sxs-lookup"><span data-stu-id="9e401-148">This issue should also be considered when designing visual and auditory feedback when looking at a target.</span></span>
<span data-ttu-id="9e401-149">尝试不要使用户塞满即时弹出效果或悬停声音。</span><span class="sxs-lookup"><span data-stu-id="9e401-149">Try not to overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="9e401-150">个很微妙为 key。</span><span class="sxs-lookup"><span data-stu-id="9e401-150">Subtlety is key.</span></span> <span data-ttu-id="9e401-151">讨论 [设计建议](eye-gaze-interaction.md#design-recommendations)时，我们将在下面讨论一些最佳实践。</span><span class="sxs-lookup"><span data-stu-id="9e401-151">We'll discuss some best practices for this further below when talking about [design recommendations](eye-gaze-interaction.md#design-recommendations).</span></span>

- <span data-ttu-id="9e401-152">**观察与控制** 假设您想要在墙壁上精确地伸直照片。</span><span class="sxs-lookup"><span data-stu-id="9e401-152">**Observation vs. control** Imagine that you want to precisely straighten a photograph on your wall.</span></span> <span data-ttu-id="9e401-153">你会参照它的边框和四周，检查它是否平齐。</span><span class="sxs-lookup"><span data-stu-id="9e401-153">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="9e401-154">现在，如果您想要使用眼睛作为输入来移动图片，则可以想象出如何实现此目的。</span><span class="sxs-lookup"><span data-stu-id="9e401-154">Now imagine how you would do that when you want to use your eye-gaze as an input to move the picture.</span></span> <span data-ttu-id="9e401-155">有点难度，对不对？</span><span class="sxs-lookup"><span data-stu-id="9e401-155">Difficult, isn't it?</span></span> <span data-ttu-id="9e401-156">这介绍了输入和控制需要时，眼睛的双重角色。</span><span class="sxs-lookup"><span data-stu-id="9e401-156">This describes the double role of eye-gaze when it's required both for input and control.</span></span> 

- <span data-ttu-id="9e401-157">**在单击前保留：** 对于快速目标选择，研究表明，用户的眼睛可以在结束手动单击 (例如，单击) 。</span><span class="sxs-lookup"><span data-stu-id="9e401-157">**Leave before click:** For quick target selections, research has shown that a user's eye-gaze can move on before concluding a manual click (for example, an air tap).</span></span> <span data-ttu-id="9e401-158">请特别注意，将速度缓慢的控制输入与慢速控制输入 (例如，语音、动手、控制器) 同步。</span><span class="sxs-lookup"><span data-stu-id="9e401-158">Pay special attention to synchronizing the fast eye-gaze signal with slower control input (for example, voice, hands, controller).</span></span>

- <span data-ttu-id="9e401-159">**小型目标：** 当您尝试读取只是太小而无法阅读的文本时，您是否知道这种感觉？</span><span class="sxs-lookup"><span data-stu-id="9e401-159">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to read comfortably?</span></span> <span data-ttu-id="9e401-160">这种令人厌烦的感觉会使您感到厌倦和磨损，因为您尝试重新调整您的眼睛，使其更好地专注。</span><span class="sxs-lookup"><span data-stu-id="9e401-160">This straining feeling on your eyes can cause you to feel tired and worn out, because you try to readjust your eyes to focus better.</span></span>
<span data-ttu-id="9e401-161">当你强制用户使用目视目标选择在你的应用程序中太小的目标时，你可以在用户中调用这种感觉。</span><span class="sxs-lookup"><span data-stu-id="9e401-161">This is a feeling you might invoke in your users when forcing them to select targets that are too small in your application using eye targeting.</span></span>
<span data-ttu-id="9e401-162">在设计方面，为了给用户建立一种愉悦舒适的体验，我们建议目标至少在 2° 的视角范围内，最好是再大一些。</span><span class="sxs-lookup"><span data-stu-id="9e401-162">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="9e401-163">**眼睛不规则的运动** 我们的眼睛执行从固定到固定的快速移动。</span><span class="sxs-lookup"><span data-stu-id="9e401-163">**Ragged eye-gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="9e401-164">观察录制的眼部运动扫描路径时你会发现，这些路径看起来是不规则的。</span><span class="sxs-lookup"><span data-stu-id="9e401-164">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="9e401-165">您的眼睛会在与 *打印头* 或 *手间运动* 比较的情况中快速跳转。</span><span class="sxs-lookup"><span data-stu-id="9e401-165">Your eyes move quickly and in spontaneous jumps in comparison to *head-gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="9e401-166">**跟踪可靠性：** 当眼睛调整到新的条件时，眼睛跟踪准确性可能会降低变化的光线。</span><span class="sxs-lookup"><span data-stu-id="9e401-166">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eyes adjust to the new conditions.</span></span>
<span data-ttu-id="9e401-167">尽管这不会影响应用程序的设计，因为准确性应该在2°限制范围内，因此，用户可能需要重新校准。</span><span class="sxs-lookup"><span data-stu-id="9e401-167">While this shouldn't necessarily affect your application design, as the accuracy should be within the 2° limitation, it may be necessary for the user to calibrate again.</span></span> 


## <a name="design-recommendations"></a><span data-ttu-id="9e401-168">设计建议</span><span class="sxs-lookup"><span data-stu-id="9e401-168">Design recommendations</span></span>
<span data-ttu-id="9e401-169">下面是基于目视输入的所述优点和挑战的特定设计建议列表：</span><span class="sxs-lookup"><span data-stu-id="9e401-169">The following is a list of specific design recommendations based on the described advantages and challenges for eye-gaze input:</span></span>

1. <span data-ttu-id="9e401-170">**眼睛看不到打印头：**</span><span class="sxs-lookup"><span data-stu-id="9e401-170">**Eye-gaze isn't the same as Head-gaze:**</span></span>
    - <span data-ttu-id="9e401-171">**考虑快速但不规则的眼睛是否符合输入任务：** 虽然我们的快速而引人注目的变动非常适合于在我们的视图中快速选择目标，但它不太适用于需要平滑输入轨迹的任务 (例如，绘制或 encircling 批注) 。</span><span class="sxs-lookup"><span data-stu-id="9e401-171">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great at quickly selecting targets across our field of view, it's less applicable for tasks that require smooth input trajectories (for example, drawing or encircling annotations).</span></span> <span data-ttu-id="9e401-172">在这种情况下，应该首选手部或头部指向。</span><span class="sxs-lookup"><span data-stu-id="9e401-172">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="9e401-173">**避免将某些内容直接附加到用户的眼睛 (例如，) 滑块或光标。**</span><span class="sxs-lookup"><span data-stu-id="9e401-173">**Avoid attaching something directly to the user’s eye-gaze (for example, a slider or cursor).**</span></span>
<span data-ttu-id="9e401-174">使用游标时，这可能会导致 "fleeing cursor" 效果，因为预计的眼睛眼睛信号略有偏移。</span><span class="sxs-lookup"><span data-stu-id="9e401-174">With cursors, this may result in a "fleeing cursor" effect because of slight offsets in the projected eye-gaze signal.</span></span> <span data-ttu-id="9e401-175">使用滑块时，它可能与用眼睛控制滑块的双角色冲突，同时还需要检查对象是否位于正确的位置。</span><span class="sxs-lookup"><span data-stu-id="9e401-175">With a slider, it can conflict with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="9e401-176">对于滑块的示例，最好将眼睛与手势结合使用。</span><span class="sxs-lookup"><span data-stu-id="9e401-176">For the example of the slider, it makes more sense to use eye-gaze in combination with hand gestures.</span></span> <span data-ttu-id="9e401-177">这意味着用户可以在多个滑杆之间快速轻松地进行切换，并收缩其拇指和食指来抓住和移动它。</span><span class="sxs-lookup"><span data-stu-id="9e401-177">This means that the user could quickly and effortlessly switch among many sliders, raising up their hand and pinching their thumb and index finger to grab and move it.</span></span> <span data-ttu-id="9e401-178">当释放了该收缩时，滑块将停止移动。</span><span class="sxs-lookup"><span data-stu-id="9e401-178">When the pinch is released, the slider stops moving.</span></span> <span data-ttu-id="9e401-179">用户可能会被淹没和分散注意力，尤其是在信号对于该用户不精确的情况下。</span><span class="sxs-lookup"><span data-stu-id="9e401-179">Users could become overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="9e401-180">将 **眼睛与其他输入组合在一起：** 将眼睛跟踪与其他输入（如手势、语音命令或按钮按下）的集成具有以下优点：</span><span class="sxs-lookup"><span data-stu-id="9e401-180">**Combine eye-gaze with other inputs:** The integration of eye tracking with other inputs, such as hand gestures, voice commands or button presses, provides several advantages:</span></span>
    - <span data-ttu-id="9e401-181">**允许免费观察：** 考虑到我们的主要角色是观察我们的环境，在不触发任何 (视觉、听觉) 反馈或操作的情况下，允许用户进行查找，这一点很重要。</span><span class="sxs-lookup"><span data-stu-id="9e401-181">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it's important that users are allowed to look around without triggering any (visual, auditory, and so on) feedback or actions.</span></span> 
    <span data-ttu-id="9e401-182">将目视跟踪与其他输入控件结合起来允许在目视跟踪观察和输入控制模式之间平稳过渡。</span><span class="sxs-lookup"><span data-stu-id="9e401-182">Combining eye tracking with another input control allows smooth transitioning between eye tracking observation and input control modes.</span></span>
  
    - <span data-ttu-id="9e401-183">**强大的上下文提供程序：** 使用有关用户在查找语音命令或使用手形笔势时所处的位置和内容的信息，可让输入排列。</span><span class="sxs-lookup"><span data-stu-id="9e401-183">**Powerful context provider:** Using information about where and what the user is looking at while saying a voice command or using a hand gesture allows seamlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="9e401-184">例如：说 _"将其放在此处"_ ，可以通过查看目标及其预期目标来流畅地选择并在场景中放置一个全息影像。</span><span class="sxs-lookup"><span data-stu-id="9e401-184">For example: Say _"put that there"_ to quickly and fluently select and position a hologram across the scene by looking at a target and its intended destination.</span></span> 

    - <span data-ttu-id="9e401-185">**同步各模输入需要：** 将快速目视运动与更复杂的输入（例如长时间的语音命令或手势）相结合，可以在完成和识别额外的输入命令之前，满足用户已继续查找的风险。</span><span class="sxs-lookup"><span data-stu-id="9e401-185">**Need for synchronizing multimodal inputs:** Combining rapid eye movements with more complex inputs, such as long voice commands or hand gestures, bears the risk that the user already continues to look around before the extra input command is finished and recognized.</span></span> <span data-ttu-id="9e401-186">如果创建自己的输入控件 (例如，) 自定义手势，请确保记录此输入或大致持续时间的开始，以将其与用户过去查看的内容相关联。</span><span class="sxs-lookup"><span data-stu-id="9e401-186">If you create your own input controls (for example, custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had looked at in the past.</span></span>
    
3. <span data-ttu-id="9e401-187">**目视跟踪输入的细微反馈：** 当查看目标以指示系统正在按预期工作但应保持微妙时，提供反馈很有用。</span><span class="sxs-lookup"><span data-stu-id="9e401-187">**Subtle feedback for eye tracking input:** It's useful to provide feedback when a target is looked at to indicate that the system is working as intended but should be kept subtle.</span></span> <span data-ttu-id="9e401-188">这可能包括缓慢的混合和缩小、视觉对象突出显示或执行其他微妙目标行为（如缓慢运动），如稍微增加目标大小。</span><span class="sxs-lookup"><span data-stu-id="9e401-188">This can include slowly blending in and out, visual highlights, or doing other subtle target behaviors, such as slow motions, such as slightly increasing the target size.</span></span> <span data-ttu-id="9e401-189">这表示系统正确检测到用户正在查看目标，而不会中断用户的当前工作流。</span><span class="sxs-lookup"><span data-stu-id="9e401-189">This indicates that the system correctly detected that the user is looking at a target without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="9e401-190">**避免将非自然目视运动作为输入进行：** 不要强制用户使用特定的眼睛运动 (注视手势) 在应用程序中触发操作。</span><span class="sxs-lookup"><span data-stu-id="9e401-190">**Avoid enforcing unnatural eye movements as input:** Don't force users to use specific eye movements (gaze gestures) to trigger actions in your application.</span></span>

5. <span data-ttu-id="9e401-191">**帐户 imprecisions：** 我们区分这两种类型的 imprecisions，这些类型对用户很明显：偏移和抖动。</span><span class="sxs-lookup"><span data-stu-id="9e401-191">**Account for imprecisions:** We distinguish two types of imprecisions, which are noticeable to users: offset and jitter.</span></span> <span data-ttu-id="9e401-192">解决偏移量的最简单方法是提供足够大的目标来与进行交互。</span><span class="sxs-lookup"><span data-stu-id="9e401-192">The easiest way to address an offset is to provide sufficiently large targets to interact with.</span></span> <span data-ttu-id="9e401-193">建议使用大于2°的视觉角度作为参考。</span><span class="sxs-lookup"><span data-stu-id="9e401-193">It's suggested that you use a visual angle greater than 2° as a reference.</span></span> <span data-ttu-id="9e401-194">例如，当您拉伸 arm 时，缩略图约为2°。</span><span class="sxs-lookup"><span data-stu-id="9e401-194">For instance, your thumbnail is about 2° in visual angle when you stretch out your arm.</span></span> <span data-ttu-id="9e401-195">因此，我们的指导如下：</span><span class="sxs-lookup"><span data-stu-id="9e401-195">This leads to the following guidance:</span></span>
    - <span data-ttu-id="9e401-196">不要强制用户选择 "小目标"。</span><span class="sxs-lookup"><span data-stu-id="9e401-196">Don't force users to select tiny targets.</span></span> <span data-ttu-id="9e401-197">研究表明，如果目标非常大且系统设计良好，则用户会将其交互描述为轻松、神奇。</span><span class="sxs-lookup"><span data-stu-id="9e401-197">Research has shown that if targets are sufficiently large and system are designed well, users describe their interactions as effortless, and magical.</span></span> <span data-ttu-id="9e401-198">如果目标太小，则用户就会将体验描述为费力、令人沮丧。</span><span class="sxs-lookup"><span data-stu-id="9e401-198">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
  
<br>

<span data-ttu-id="9e401-199">此页面提供了一个很好的概述，使你开始了解红眼，作为混合现实中的输入。</span><span class="sxs-lookup"><span data-stu-id="9e401-199">This page provided you with a good overview to get you started understanding eye-gaze as an input in mixed reality.</span></span> <span data-ttu-id="9e401-200">若要开始开发，请查看我们关于 [Unity 中眼睛](/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-main) 的信息并观看 [DirectX 中的眼睛](../develop/native/gaze-in-directx.md)。</span><span class="sxs-lookup"><span data-stu-id="9e401-200">To get started developing, check out our information on [eye-gaze in Unity](/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-main) and [eye-gaze in DirectX](../develop/native/gaze-in-directx.md).</span></span>


## <a name="see-also"></a><span data-ttu-id="9e401-201">另请参阅</span><span class="sxs-lookup"><span data-stu-id="9e401-201">See also</span></span>
* [<span data-ttu-id="9e401-202">舒适</span><span class="sxs-lookup"><span data-stu-id="9e401-202">Comfort</span></span>](comfort.md)
* [<span data-ttu-id="9e401-203">目视观察 DirectX</span><span class="sxs-lookup"><span data-stu-id="9e401-203">Eye-gaze in DirectX</span></span>](../develop/native/gaze-in-directx.md)
* [<span data-ttu-id="9e401-204">眼睛 (混合现实工具包) </span><span class="sxs-lookup"><span data-stu-id="9e401-204">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-main)
* [<span data-ttu-id="9e401-205">HoloLens 2 中的眼动跟踪</span><span class="sxs-lookup"><span data-stu-id="9e401-205">Eye tracking on HoloLens 2</span></span>](eye-tracking.md)
* [<span data-ttu-id="9e401-206">凝视和提交</span><span class="sxs-lookup"><span data-stu-id="9e401-206">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="9e401-207">凝视和停留</span><span class="sxs-lookup"><span data-stu-id="9e401-207">Gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="9e401-208">语音输入</span><span class="sxs-lookup"><span data-stu-id="9e401-208">Voice input</span></span>](../out-of-scope/voice-design.md)