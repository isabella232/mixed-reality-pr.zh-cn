---
title: 基于眼睛凝视的交互
description: 了解 HoloLens 2 上的眼睛和目视交互，以及新的上下文和人员理解（如果在全息体验中获得）。
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: 眼睛跟踪，混合现实，输入，眼睛，混合现实耳机，windows Mixed reality 耳机，虚拟现实耳机，HoloLens，MRTK，混合现实 Toolkit，设计，交互
ms.openlocfilehash: aec41c6654ce10254648e90e08a09ff9adade75a3dc63af81a0953b67b95729f
ms.sourcegitcommit: a1c086aa83d381129e62f9d8942f0fc889ffcab0
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 08/05/2021
ms.locfileid: "115220953"
---
# <a name="eye-gaze-based-interaction-on-hololens-2"></a>HoloLens 2 上的目视监视交互

![MRTK 中的眼睛跟踪演示](images/mrtk_et_scenemenu.jpg)

HoloLens 2 的一项激动人心的新功能是目视跟踪。 在我们 HoloLens 2 页面上的[眼睛跟踪](eye-tracking.md)上，我们提到了需要每个用户完成[校准](/hololens/hololens-calibration)、开发人员指南和突出跟踪突出显示用例。 目视输入仍是一种新类型的用户输入，有很多东西需要学习。 

尽管眼睛输入仅在您启动 HoloLens 2) 时看到的用户界面 (的用户界面中进行了细微的输入，但多个应用程序（如["HoloLens 板块"](https://www.microsoft.com/p/mr-playground/9nb31lh723s2)）展示了如何将目视输入添加到您的全息体验的神奇示例。
在此页上，我们将讨论集成眼睛输入以与全息版应用程序进行交互的设计注意事项。

你将了解关键的优点，还会遇到一些与目视输入相关的独特挑战。 根据这些建议，我们提供了若干设计建议，以帮助你创建满足目视支持的用户界面。 

## <a name="device-support"></a>设备支持

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><strong>功能</strong></td>
     <td><a href="/hololens/hololens1-hardware"><strong>HoloLens（第 1 代）</strong></a></td>
     <td><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></td>
     <td><a href="../discover/immersive-headset-hardware-details.md"><strong>沉浸式头戴显示设备</strong></a></td>
</tr>
<tr>
     <td>眼睛-注视</td>
     <td>❌</td>
     <td>✔️</td>
     <td>❌</td>
</tr>
</table>

## <a name="head-and-eye-tracking-design-concepts-demo"></a>头部和眼动跟踪设计概念演示

若要了解头部和眼动跟踪设计概念的运行情况，请查看下面的“设计全息影像 - 头部跟踪和眼动跟踪”视频演示。 完成后，请继续详细了解特定主题。

> [!VIDEO https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Microsofts-Designing-Holograms-Head-Tracking-and-Eye-Tracking-Chapter/player]

此视频来自于“设计全息影像”HoloLens 2 应用。在[此处](https://aka.ms/dhapp)下载并享受完整体验。

## <a name="eye-gaze-input-design-guidelines"></a>目视输入设计准则

构建充分利用快速移动目视目标的交互可能会很困难。 在本部分中，我们总结了在设计应用程序时要考虑的主要优点和挑战。 

### <a name="benefits-of-eye-gaze-input"></a>目视输入的优点

- **高速指向。** 眼睛判断力是人为身体最快的响应判断力。 

- **不费力。** 几乎没有任何身体动作。 

- **隐含性。** 用户通常会将其描述为 "构思阅读"，有关用户的目视变动的信息使系统可以知道用户打算参与哪个目标。 

- **备选的输入通道。** 眼睛可为用户提供强大的支持输入，并根据用户的手眼协调从用户的经验中生成。

- **视觉注意力。** 另一个重要的优点是可以推断出用户正在关注的内容。 这可以帮助不同的应用程序领域，从更有效地评估不同设计，到协助的用户界面，增加了社交提示以进行远程通信。

简而言之，使用眼睛眼睛作为输入可提供快速且简单的上下文输入信号。 与其他输入（如 *语音* 和 *手动* 输入）结合在一起时，此功能非常强大，可以确认用户的意图。


### <a name="challenges-of-eye-gaze-as-an-input"></a>眼睛为输入的挑战

虽然眼睛可用于创建符合用户体验的用户体验，但使您感到 superhero，但也必须知道这种情况并不好。 下面的列表讨论了一些需要考虑的问题，以及如何解决这些 *问题* ，以便使用目视的输入： 

- **眼睛为 "始终打开"** 打开眼睛护盖后，眼睛开始 fixating 环境中的东西。 对每个外观作出反应并意外发出操作，因为您查看的内容太长，会导致 unsatisfying 的体验。
建议将眼睛与 *声音命令*、手势、*按钮单击* 或扩展停留结合 *起来，以* 触发选择目标 (有关详细信息，请参阅 [眼睛和提交](gaze-and-commit-eyes.md)) 。
此解决方案还允许使用一种模式，在该模式下，用户可以自由地查找，而不会因触发某些事情而 involuntarily。 当查看目标时设计视觉对象和听觉反馈时，还应考虑此问题。
尝试不要使用户塞满即时弹出效果或悬停声音。 个很微妙为 key。 讨论 [设计建议](eye-gaze-interaction.md#design-recommendations)时，我们将在下面讨论一些最佳实践。

- **观察与控制** Imagine 你希望在墙壁上准确地拉伸照片。 你会参照它的边框和四周，检查它是否平齐。 现在，如果您想要使用眼睛作为输入来移动图片，则可以想象出如何实现此目的。 有点难度，对不对？ 这介绍了输入和控制需要时，眼睛的双重角色。 

- **在单击前保留：** 对于快速目标选择，研究表明，用户的眼睛可以在结束手动单击 (例如，单击) 。 请特别注意，将速度缓慢的控制输入与慢速控制输入 (例如，语音、动手、控制器) 同步。

- **小型目标：** 当您尝试读取只是太小而无法阅读的文本时，您是否知道这种感觉？ 这种令人厌烦的感觉会使您感到厌倦和磨损，因为您尝试重新调整您的眼睛，使其更好地专注。
当你强制用户使用目视目标选择在你的应用程序中太小的目标时，你可以在用户中调用这种感觉。
在设计方面，为了给用户建立一种愉悦舒适的体验，我们建议目标至少在 2° 的视角范围内，最好是再大一些。

- **眼睛不规则的运动** 我们的眼睛执行从固定到固定的快速移动。 观察录制的眼部运动扫描路径时你会发现，这些路径看起来是不规则的。 您的眼睛会在与 *打印头* 或 *手间运动* 比较的情况中快速跳转。  

- **跟踪可靠性：** 当眼睛调整到新的条件时，眼睛跟踪准确性可能会降低变化的光线。
尽管这不会影响应用程序的设计，因为准确性应该在2°限制范围内，因此，用户可能需要重新校准。 


## <a name="design-recommendations"></a>设计建议
下面是基于目视输入的所述优点和挑战的特定设计建议列表：

1. **眼睛看不到打印头：**
    - **考虑快速但不规则的眼睛是否符合输入任务：** 虽然我们的快速而引人注目的变动非常适合于在我们的视图中快速选择目标，但它不太适用于需要平滑输入轨迹的任务 (例如，绘制或 encircling 批注) 。 在这种情况下，应该首选手部或头部指向。
  
    - **避免将某些内容直接附加到用户的眼睛 (例如，) 滑块或光标。**
使用游标时，这可能会导致 "fleeing cursor" 效果，因为预计的眼睛眼睛信号略有偏移。 使用滑块时，它可能与用眼睛控制滑块的双角色冲突，同时还需要检查对象是否位于正确的位置。 对于滑块的示例，最好将眼睛与手势结合使用。 这意味着用户可以在多个滑杆之间快速轻松地进行切换，并收缩其拇指和食指来抓住和移动它。 当释放了该收缩时，滑块将停止移动。 用户可能会被淹没和分散注意力，尤其是在信号对于该用户不精确的情况下。 
  
2. 将 **眼睛与其他输入组合在一起：** 将眼睛跟踪与其他输入（如手势、语音命令或按钮按下）的集成具有以下优点：
    - **允许免费观察：** 考虑到我们的主要角色是观察我们的环境，在不触发任何 (视觉、听觉) 反馈或操作的情况下，允许用户进行查找，这一点很重要。 
    将目视跟踪与其他输入控件结合起来允许在目视跟踪观察和输入控制模式之间平稳过渡。
  
    - **强大的上下文提供程序：** 使用有关用户在查找语音命令或使用手形笔势时所处的位置和内容的信息，可让输入排列。 例如：说 _"将其放在此处"_ ，可以通过查看目标及其预期目标来流畅地选择并在场景中放置一个全息影像。 

    - **同步各模输入需要：** 将快速目视运动与更复杂的输入（例如长时间的语音命令或手势）相结合，可以在完成和识别额外的输入命令之前，满足用户已继续查找的风险。 如果创建自己的输入控件 (例如，) 自定义手势，请确保记录此输入或大致持续时间的开始，以将其与用户过去查看的内容相关联。
    
3. **目视跟踪输入的细微反馈：** 当查看目标以指示系统正在按预期工作但应保持微妙时，提供反馈很有用。 这可能包括缓慢的混合和缩小、视觉对象突出显示或执行其他微妙目标行为（如缓慢运动），如稍微增加目标大小。 这表示系统正确检测到用户正在查看目标，而不会中断用户的当前工作流。 

4. **避免将非自然目视运动作为输入进行：** 不要强制用户使用特定的眼睛运动 (注视手势) 在应用程序中触发操作。

5. **帐户 imprecisions：** 我们区分这两种类型的 imprecisions，这些类型对用户很明显：偏移和抖动。 解决偏移量的最简单方法是提供足够大的目标来与进行交互。 建议使用大于2°的视觉角度作为参考。 例如，当您拉伸 arm 时，缩略图约为2°。 因此，我们的指导如下：
    - 不要强制用户选择 "小目标"。 研究表明，如果目标非常大且系统设计良好，则用户会将其交互描述为轻松、神奇。 如果目标太小，则用户就会将体验描述为费力、令人沮丧。
  
<br>

此页面提供了一个很好的概述，使你开始了解红眼，作为混合现实中的输入。 若要开始开发，请查看我们关于 [Unity 中眼睛](/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-main) 的信息并观看 [DirectX 中的眼睛](../develop/native/gaze-in-directx.md)。


## <a name="see-also"></a>另请参阅
* [舒适](comfort.md)
* [目视观察 DirectX](../develop/native/gaze-in-directx.md)
* [眼睛 (混合现实 Toolkit) ](/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-main)
* [HoloLens 2 中的眼动跟踪](eye-tracking.md)
* [凝视和提交](gaze-and-commit.md)
* [凝视和停留](gaze-and-dwell.md)
* [语音输入](../out-of-scope/voice-design.md)