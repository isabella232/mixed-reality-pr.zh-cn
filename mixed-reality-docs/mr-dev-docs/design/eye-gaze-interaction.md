---
title: 基于眼睛凝视的交互
description: 了解 HoloLens 2 上的眼睛和目视交互，以及新级别的上下文和人工理解（如果在全息体验中获得）。
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: 目视跟踪，混合现实，输入，眼睛，混合现实耳机，windows Mixed reality 耳机，虚拟现实耳机，HoloLens，MRTK，混合现实工具包，设计，交互
ms.openlocfilehash: 207f8d0f179f722a2e4dd6d6e2bdd9cbf75b2250
ms.sourcegitcommit: 8f141a843bcfc57e1b18cc606292186b8ac72641
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 05/19/2021
ms.locfileid: "110196572"
---
# <a name="eye-gaze-based-interaction-on-hololens-2"></a>HoloLens 2 上基于目视的目视交互

![MRTK 中的眼睛跟踪演示](images/mrtk_et_scenemenu.jpg)

HoloLens 2 上令人兴奋的新功能之一是目视跟踪。 在我们的 " [HoloLens 2](eye-tracking.md) " 页面上，我们提到了对每个用户进行 [校准](/hololens/hololens-calibration)的需求，提供了一些开发人员指南和突出跟踪的突出显示用例。 目视输入仍是一种新类型的用户输入，有很多东西需要学习。 

尽管眼睛输入仅在板块的用户界面 (在您启动 HoloLens 2) 时看到的用户界面，但多个应用程序（例如 ["Hololens"](https://www.microsoft.com/p/mr-playground/9nb31lh723s2)）的情况下显示了很好的示例，其中展示了目视输入如何添加到您的全息体验的神奇之处。
在此页上，我们将讨论集成眼睛输入以与全息版应用程序进行交互的设计注意事项。

你将了解关键的优点，还会遇到一些与目视输入相关的独特挑战。 根据这些建议，我们提供了若干设计建议，以帮助你创建满足目视支持的用户界面。 

## <a name="device-support"></a>设备支持

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><strong>功能</strong></td>
     <td><a href="/hololens/hololens1-hardware"><strong>HoloLens（第 1 代）</strong></a></td>
     <td><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></td>
     <td><a href="../discover/immersive-headset-hardware-details.md"><strong>沉浸式头戴显示设备</strong></a></td>
</tr>
<tr>
     <td>眼睛-注视</td>
     <td>❌</td>
     <td>✔️</td>
     <td>❌</td>
</tr>
</table>

## <a name="head-and-eye-tracking-design-concepts-demo"></a>标题和眼睛跟踪设计概念演示

若要查看标题和目视跟踪的设计概念，请参阅下面的 **设计全息影像-打印头跟踪和眼睛跟踪** 视频演示。 完成后，请继续详细了解特定主题。

> [!VIDEO https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Microsofts-Designing-Holograms-Head-Tracking-and-Eye-Tracking-Chapter/player]

*此视频取自 "设计全息影像" HoloLens 2 应用。下载并在 [此处](https://aka.ms/dhapp)享受完全体验。*

## <a name="eye-gaze-input-design-guidelines"></a>目视输入设计准则

构建充分利用快速移动目视目标的交互可能会很困难。 本部分汇总了设计应用程序时要考虑的主要优点和难题。 

### <a name="benefits-of-eye-gaze-input"></a>眼睛凝视输入的好处

- **高速指向。** 眼睛眼部是人体中反应速度最快的眼部。 

- **不费力。** 几乎没有任何身体动作。 

- **隐含性。** 有关用户眼睛运动的信息通常被用户描述为"思维读取"，让系统知道用户计划参与的目标。 

- **备选的输入通道。** 眼睛凝视可以为用户提供强大的支持输入，以基于用户的手部协调，基于他们多年来的经验构建手部和语音输入。

- **视觉注意力。** 另一个重要好处是能够推断出用户关注什么。 这可在各种应用程序领域提供帮助，包括更有效地评估不同的设计，以及帮助更智能的用户界面和增强的远程通信社交提示。

简而言之，使用眼睛凝视作为输入可提供快速轻松的上下文输入信号。 当与其他输入（如语音和手动输入）结合使用以确认用户的意图时，此功能非常强大。


### <a name="challenges-of-eye-gaze-as-an-input"></a>作为输入的眼睛凝视的挑战

虽然眼睛凝视可用于创建令人满足的用户体验，让你感觉自己像超级用户，但必须知道哪一点不适合适当考虑这一点。这一点也很重要。 以下列表讨论了在使用 *眼睛* 凝视输入时要考虑的一些难题以及如何解决这些问题： 

- **眼睛凝视是"始终打开"** 一打开眼睛的眼圈，眼睛就开始固定环境中的东西。 响应你做出的每一个外观并意外发出操作，因为你查看了太长内容，将导致不满足体验。
建议将眼睛凝视与语音命令、手势、按钮单击或延长停留相结合，以触发目标 (有关详细信息，请参阅眼睛凝视和提交) 。 [](gaze-and-commit-eyes.md)
此解决方案还允许一种模式，在此模式下，用户可以自由地四处查看，而不会因不由自主地触发某些内容而感到重负。 当查看目标时设计视觉对象和听觉反馈时，还应考虑此问题。
尝试不要使用户塞满即时弹出效果或悬停声音。 个很微妙为 key。 讨论 [设计建议](eye-gaze-interaction.md#design-recommendations)时，我们将在下面讨论一些最佳实践。

- **观察与控制** 假设您想要在墙壁上精确地伸直照片。 你会参照它的边框和四周，检查它是否平齐。 现在，如果您想要使用眼睛作为输入来移动图片，则可以想象出如何实现此目的。 有点难度，对不对？ 这介绍了输入和控制需要时，眼睛的双重角色。 

- **在单击前保留：** 对于快速目标选择，研究表明，用户的眼睛可以在结束手动单击 (例如，单击) 。 请特别注意，将速度缓慢的控制输入与慢速控制输入 (例如，语音、动手、控制器) 同步。

- **小型目标：** 当您尝试读取只是太小而无法阅读的文本时，您是否知道这种感觉？ 这种令人厌烦的感觉会使您感到厌倦和磨损，因为您尝试重新调整您的眼睛，使其更好地专注。
当你强制用户使用目视目标选择在你的应用程序中太小的目标时，你可以在用户中调用这种感觉。
在设计方面，为了给用户建立一种愉悦舒适的体验，我们建议目标至少在 2° 的视角范围内，最好是再大一些。

- **眼睛不规则的运动** 我们的眼睛执行从固定到固定的快速移动。 观察录制的眼部运动扫描路径时你会发现，这些路径看起来是不规则的。 您的眼睛会在与 *打印头* 或 *手间运动* 比较的情况中快速跳转。  

- **跟踪可靠性：** 当眼睛调整到新的条件时，眼睛跟踪准确性可能会降低变化的光线。
尽管这不会影响应用程序的设计，因为准确性应该在2°限制范围内，因此，用户可能需要重新校准。 


## <a name="design-recommendations"></a>设计建议
下面是基于目视输入的所述优点和挑战的特定设计建议列表：

1. **眼睛看不到打印头：**
    - **考虑快速但不规则眼部运动是否适合输入任务：** 虽然快速不规则眼睛运动非常适用于快速选择整个视场中的目标，但它不太适用于需要平滑输入轨迹的任务 (例如，绘制或围绕) 。 在这种情况下，应该首选手部或头部指向。
  
    - **避免将某些内容直接附加到用户的视线，例如 (滑块或光标) 。**
使用光标时，由于预测眼睛凝视信号中略有偏移，这可能会导致"光标闪烁"效果。 使用滑块时，它可能会与双角色冲突：用眼睛控制滑块，同时还要检查对象是否位于正确的位置。 对于滑块的示例，将眼睛凝视与手势结合使用更有意义。 这意味着，用户可以快速轻松地在许多滑块间切换，提升手部并捏合手指和手指来抓取和移动滑块。 释放收缩时，滑块停止移动。 用户可能会感到重负和分散注意力，尤其是在信号不精确时。 
  
2. **将眼睛凝视与其他输入相结合：** 眼动跟踪与其他输入（如手势、语音命令或按钮按下）的集成提供以下优势：
    - **允许免费观察：** 鉴于我们眼睛的主要角色是观察环境，因此，必须允许用户四处查看，而不触发任何 (视觉对象、审核等) 反馈或操作。 
    将眼动跟踪与另一个输入控件相结合，可以在眼动跟踪观察和输入控制模式之间顺利转换。
  
    - **功能强大的上下文提供程序：** 使用有关用户在说语音命令时正在查看什么位置和内容的信息，或者使用手势，可以跨视场无缝地通道输入。 例如：说 _"将其放在此处"_ ，可以通过查看目标及其预期目标来流畅地选择并在场景中放置一个全息影像。 

    - **同步各模输入需要：** 将快速目视运动与更复杂的输入（例如长时间的语音命令或手势）相结合，可以在完成和识别额外的输入命令之前，满足用户已继续查找的风险。 如果创建自己的输入控件 (例如，) 自定义手势，请确保记录此输入或大致持续时间的开始，以将其与用户过去查看的内容相关联。
    
3. **目视跟踪输入的细微反馈：** 当查看目标以指示系统正在按预期工作但应保持微妙时，提供反馈很有用。 这可能包括缓慢的混合和缩小、视觉对象突出显示或执行其他微妙目标行为（如缓慢运动），如稍微增加目标大小。 这表示系统正确检测到用户正在查看目标，而不会中断用户的当前工作流。 

4. **避免将非自然目视运动作为输入进行：** 不要强制用户使用特定的眼睛运动 (注视手势) 在应用程序中触发操作。

5. **帐户 imprecisions：** 我们区分这两种类型的 imprecisions，这些类型对用户很明显：偏移和抖动。 解决偏移量的最简单方法是提供足够大的目标来与进行交互。 建议使用大于2°的视觉角度作为参考。 例如，当您拉伸 arm 时，缩略图约为2°。 因此，我们的指导如下：
    - 不要强制用户选择 "小目标"。 研究表明，如果目标非常大且系统设计良好，则用户会将其交互描述为轻松、神奇。 如果目标太小，则用户就会将体验描述为费力、令人沮丧。
  
<br>

本页提供了一个很好的概述，让你开始将眼睛凝视理解为混合现实中的输入。 若要开始开发，请查看有关 Unity 中眼睛凝视 [和](https://aka.ms/mrtk-eyes) [DirectX](../develop/native/gaze-in-directx.md)中眼睛凝视的信息。


## <a name="see-also"></a>另请参阅
* [舒适](comfort.md)
* [DirectX 中的眼睛凝视](../develop/native/gaze-in-directx.md)
* [Unity 中的眼睛凝视 (混合现实工具包) ](https://aka.ms/mrtk-eyes)
* [HoloLens 2 中的眼动跟踪](eye-tracking.md)
* [凝视和提交](gaze-and-commit.md)
* [凝视和停留](gaze-and-dwell.md)
* [语音输入](../out-of-scope/voice-design.md)